---
title: "Cleaning and Aggregating UCI HAR Sensor Data"
author: "Payam Bahreyni"
date: "2015-08-23"
output: 
  html_document: 
    self_contained: no
categories: [projects]
tags: [data cleaning, tidy datasets, r, UCI, HAR, sensor data]
---
**Purpose:** Integrating and consolidating data from multiple sources.

**Context:** In this project, data for Human Activity Recognition[^1] (HAR) [project](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) from UCI Machine Learning Repository is downloaded, cleaned, and aggregated as a tidy data set. I have done this project as the course project for "Getting and Cleaning Data" in [Data Science Specialization](https://www.coursera.org/specializations/jhu-data-science) by John Hopkins University offered at Coursera.

[^1]: Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.

**Challenge:** The data for this project is dispersed across multiple files:

 * **X_train.txt**: predictor feature values (normalized -1 to 1)
 * **y_train.txt**: class labels (1 to 6)
 * **subject_train.text**: subject identifier (1 to 30)
 * **features.txt**: feature names
 
These files need to be merged and consolidated into a tidy dataframe before any meaningful analysis can be performed. Moreover, most data analysis, visualization, and machine learning libraries require data to be in a tidy dataframe.

**Project URL:** [Cleaning and Aggregating UCI HAR Sensor Data](https://github.com/pbahr/aggregating_UCI_HAR_sensor_data)

## Initial Setup

First, we need to download the data, and unzip it.
```{r}
knitr::opts_knit$set(root.dir="..")
```

```{r}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"

if (!file.exists("dataset.zip")) {
    download.file(fileURL, "dataset.zip", method = "curl")
}

unzip("dataset.zip")
```

```{r}
# Loading training data
train_X <- read.table("UCI HAR Dataset/train/X_train.txt")
train_Y <- read.table("UCI HAR Dataset/train/y_train.txt")
train_subjects <- read.table("UCI HAR Dataset/train/subject_train.txt")

# Feature names
features <- read.table("UCI HAR Dataset/features.txt", stringsAsFactors = F)

# assemble training data set
train <- train_X
names(train) <- features$V2
train$subject <- train_subjects[[1]]
train$activity <- train_Y[[1]]

#cleanup
rm(train_Y)
rm(train_subjects)
rm(train_X)

# assemble test data
test_X <- read.table("UCI HAR Dataset/test/X_test.txt")
test_Y <- read.table("UCI HAR Dataset/test/y_test.txt")
test_subjects <- read.table("UCI HAR Dataset/test/subject_test.txt")

# putting test data together
test <- test_X
names(test) <- features$V2
test$subject <- test_subjects[[1]]
test$activity <- test_Y[[1]]

# cleanup
rm(test_X)
rm(test_Y)
rm(test_subjects)
rm(features)

# put everything together
dataset <- rbind(train, test, make.row.names= T)

library(dplyr)

# Make syntactically valid column names, otherwise we get duplicate columns error
names <- make.names(names(dataset), unique = T)
names(dataset) <- names

# create data frame table
clean <- tbl_df(dataset)

# reorder columns, keep only mean and std columns
clean <- select(clean, subject, activity, contains("mean"), contains("std"))

# Activity labels
activity <- read.table("UCI HAR Dataset/activity_labels.txt")

# Join data with activity labels
clean <- merge(clean, activity, by.x = "activity", by.y= "V1")

# Rename activity_label column, reorder,  and remove extra columns
clean <- rename(clean, activity_label = V2)
clean <- select(clean, subject, activity_label, -activity, 3:89)

# Create grouped data set by subject and activity
clean_grouped <- group_by(clean, subject, activity_label)
avg <- summarise_each(clean_grouped, funs(mean))

# Write output
write.table(avg, "avg.txt", row.names = F)
```
